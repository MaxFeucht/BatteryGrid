{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def elongate(df):\n",
    "    df_long = pd.wide_to_long(df, i = \"PRICES\", j = \"hour\", stubnames=[\"Hour\"], sep = \" \").reset_index()\n",
    "    df_long.rename(columns={\"Hour\": \"price\", \"PRICES\": \"date\"}, inplace = True)\n",
    "    df_long['datetime'] = pd.to_datetime(df_long['date']) + pd.to_timedelta(df_long['hour'], unit='h')\n",
    "    df_long.sort_values(['datetime'], ascending=[True], inplace=True)\n",
    "    df_long['price'] = df_long['price'].astype(float) / 1000 # Convert price per MWh to price per KWh\n",
    "    return df_long\n",
    "\n",
    "# delete date:time column\n",
    "train = elongate(pd.read_excel('data/train.xlsx'))\n",
    "val = elongate(pd.read_excel('data/validate.xlsx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  hour    price\n",
      "0    2007-01-01     1  0.02431\n",
      "1096 2007-01-01     2  0.02431\n",
      "2192 2007-01-01     3  0.02171\n",
      "3288 2007-01-01     4  0.00842\n",
      "4384 2007-01-01     5  0.00001\n",
      "0.01601\n",
      "   index       date  hour    price\n",
      "0      0 2007-01-01     1  0.02431\n",
      "1   1096 2007-01-01     2  0.02431\n",
      "2   2192 2007-01-01     3  0.02171\n",
      "3   3288 2007-01-01     4  0.00842\n",
      "4   4384 2007-01-01     5  0.00001\n",
      "0.02431\n"
     ]
    }
   ],
   "source": [
    "# clean up datetime column\n",
    "del train['datetime']\n",
    "del val['datetime']\n",
    "\n",
    "# We should fix the loc of the train data to 0,1,2 etc\n",
    "print(train.head())\n",
    "print(train.loc[1, 'price'])\n",
    "train.reset_index(inplace=True)\n",
    "print(train.head())\n",
    "print(train.loc[1, 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index       date  hour    price  gradient_2  gradient_1  second_gradient_1  \\\n",
      "0      0 2007-01-01     1  0.02431     0.00000     0.00000            0.00000   \n",
      "1   1096 2007-01-01     2  0.02431     0.00000     0.00000            0.00000   \n",
      "2   2192 2007-01-01     3  0.02171    -0.00260    -0.00260           -0.00260   \n",
      "3   3288 2007-01-01     4  0.00842    -0.01589    -0.01329           -0.01069   \n",
      "4   4384 2007-01-01     5  0.00001    -0.02170    -0.00841            0.00488   \n",
      "\n",
      "   second_gradient_2  \n",
      "0            0.00000  \n",
      "1            0.00000  \n",
      "2           -0.00260  \n",
      "3           -0.01329  \n",
      "4           -0.00581  \n"
     ]
    }
   ],
   "source": [
    "### GRADIENT FEATURES ### Q: Is trend a better name?\n",
    "def gradient_features(data, num_prev_points=1):\n",
    "    for i in range(len(data) - 1):\n",
    "        if i == 0:\n",
    "            data.loc[i, f'gradient_{num_prev_points}'] = 0\n",
    "        else:\n",
    "            gradient_sum = 0\n",
    "            for j in range(num_prev_points):\n",
    "                location_point_a = max(i - j, 0)\n",
    "                location_point_b = max(i - j - 1, 1)\n",
    "                point_a = data.loc[location_point_a, 'price']\n",
    "                point_b = data.loc[location_point_b, 'price']\n",
    "                gradient_sum += point_a - point_b\n",
    "\n",
    "            data.loc[i, f'gradient_{num_prev_points}'] = gradient_sum \n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def second_gradient_features(data, num_prev_points=1):\n",
    "    # check if gradient_1 column exists\n",
    "    if 'gradient_1' not in data.columns:\n",
    "        data = gradient_features(data, num_prev_points=1)\n",
    "    \n",
    "    for i in range(len(data) - 1):\n",
    "        if i == 0:\n",
    "            data.loc[i, f'second_gradient_{num_prev_points}'] = 0\n",
    "        else:\n",
    "            second_gradient_sum = 0\n",
    "\n",
    "            for j in range(num_prev_points): # for amount of num_prev_points compare to the previous point\n",
    "                location_point_a = max(i - j, 0)\n",
    "                location_point_b = max(i - j - 1, 1)\n",
    "                point_a = data.loc[location_point_a, 'gradient_1']\n",
    "                point_b = data.loc[location_point_b, 'gradient_1']\n",
    "                second_gradient_sum += point_a - point_b\n",
    "            \n",
    "            data.loc[i, f'second_gradient_{num_prev_points}'] = second_gradient_sum    \n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# # TEST\n",
    "# test = [1, 2, 4, 7, 6, 5]\n",
    "\n",
    "# # make test dataframe\n",
    "# test = pd.DataFrame(test, columns=['price'])\n",
    "\n",
    "\n",
    "# test = gradient_features(test, num_prev_points=1)\n",
    "# test = second_gradient_features(test, num_prev_points=1)\n",
    "\n",
    "# print(test.head())\n",
    "train = gradient_features(train, num_prev_points=2)\n",
    "train = second_gradient_features(train, num_prev_points=2)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  hour    price  gradient_2  gradient_1  fourier_freq_1  \\\n",
      "0    2007-01-01     1  0.02431     0.00000     0.00000             NaN   \n",
      "1096 2007-01-01     2  0.02431     0.00668     0.00668       -0.041667   \n",
      "2192 2007-01-01     3  0.02171     0.00956     0.00956        0.083333   \n",
      "3288 2007-01-01     4  0.00842    -0.00179    -0.00179        0.041667   \n",
      "4384 2007-01-01     5  0.00001    -0.00888    -0.00888        0.041667   \n",
      "\n",
      "      fourier_freq_2  fourier_freq_3  \n",
      "0                NaN             NaN  \n",
      "1096        0.041667        0.083333  \n",
      "2192       -0.083333        0.013889  \n",
      "3288       -0.041667        0.013889  \n",
      "4384       -0.041667        0.013889  \n"
     ]
    }
   ],
   "source": [
    "### FOURIER TRANSFORM ###\n",
    "\n",
    "def fourier_top_freq(data, segment_size=72):\n",
    "    '''\n",
    "    Applies Fourier transform to segments of the 'price' data and extracts the top 3 frequencies.\n",
    "    \n",
    "    Parameters:\n",
    "    data (DataFrame): Input data.\n",
    "    segment_size (int): Number of data points in each segment for Fourier transform.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: The input data with top 3 Fourier frequencies for each segment.\n",
    "    '''\n",
    "\n",
    "    # Create new columns for the top 3 fourier frequencies\n",
    "    for i in range(3):\n",
    "        data[f'fourier_freq_{i + 1}'] = np.nan\n",
    "\n",
    "    # For each range of data points, calculate the Fourier transform\n",
    "    for i in range(segment_size, len(data), 1): # Start at <segment_size>\n",
    "        # Fourier transform of the last <segment_size> data points\n",
    "        segment = data['price'][i - segment_size:i]\n",
    "        fourier_coeffs = np.fft.fft(segment)\n",
    "        freqs = np.fft.fftfreq(segment_size, d=1)  # Assuming hourly data, hence d=1\n",
    "\n",
    "        # Get indices of top 3 frequencies based on magnitude of Fourier coefficients\n",
    "        indices = np.argsort(np.abs(fourier_coeffs))[::-1][1:4] # ::-1 to sort in descending order\n",
    "\n",
    "        for j in range(3):\n",
    "            column_name = f'fourier_freq_{j + 1}'\n",
    "            data.loc[i, column_name] = freqs[indices[j]]\n",
    "\n",
    "    return data\n",
    "\n",
    "train = fourier_top_freq(train, segment_size=72)\n",
    "val = fourier_top_freq(val)\n",
    "\n",
    "print(train.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HISTORIC FEATURES ###\n",
    "\n",
    "def moving_averages(data, window_size=72):\n",
    "    '''\n",
    "    Calculates the moving average of the 'price' data for each data point.\n",
    "\n",
    "    '''\n",
    "    data['moving_average'] = data['price'].rolling(window=window_size, min_periods=1).mean()\n",
    "    return data\n",
    "\n",
    "def moving_std(data, window_size=72):\n",
    "    data['moving_std'] = data['price'].rolling(window=window_size, min_periods=1).std()\n",
    "    return data\n",
    "\n",
    "def moving_min(data, window_size=72):\n",
    "    data['moving_min'] = data['price'].rolling(window=window_size, min_periods=1).min()\n",
    "    return data\n",
    "\n",
    "def moving_max(data, window_size=72):\n",
    "    data['moving_max'] = data['price'].rolling(window=window_size, min_periods=1).max()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATE FEATURES ###\n",
    "def date_features(data):\n",
    "    data['day_of_week'] = data['datetime'].dt.dayofweek\n",
    "    data['day_of_month'] = data['datetime'].dt.day\n",
    "    data['month'] = data['datetime'].dt.month\n",
    "    data['year'] = data['datetime'].dt.year\n",
    "    data['hour'] = data['datetime'].dt.hour\n",
    "    data['season'] = (data['month'] % 12 + 3) // 3\n",
    "    return data\n",
    "\n",
    "def average_features(data):\n",
    "    # Lets reconsider to not use this it feels like it would not translate well to the tests set\n",
    "    data['average_day'] = data.groupby(['day_of_week', 'hour'])['price'].transform('mean')\n",
    "    data['average_day_of_month'] = data.groupby(['day_of_month', 'hour'])['price'].transform('mean')\n",
    "    \n",
    "    data['average_month'] = data.groupby(['month', 'hour'])['price'].transform('mean')\n",
    "    data['average_season'] = data.groupby(['season', 'hour'])['price'].transform('mean')\n",
    "    return data\n",
    "\n",
    "train = date_features(train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
